{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3a642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from mlforecast import MLForecast\n",
    "from mlforecast.lag_transforms import Combine, RollingMean\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fc79fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data\n",
    "future_values = pd.read_csv('future_values.csv',parse_dates = ['date']).rename(columns={'date':'ds','store_id':'unique_id'})\n",
    "metadata = pd.read_csv('metadata.csv').rename(columns={'store_id':'unique_id'})\n",
    "sales_data = pd.read_csv('sales_data.csv',parse_dates = ['date']).rename(columns={'date':'ds','store_id':'unique_id','sales':'y'})\n",
    "sales_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48cdd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping data by each time series\n",
    "grouped = sales_data.groupby('unique_id')\n",
    "\n",
    "print(\"\\nDate range per unique_id:\")\n",
    "date_range = sales_data.groupby('unique_id')['ds'].agg(['min', 'max', 'count'])\n",
    "print(date_range)\n",
    "\n",
    "# Creating a summary dataframe for visualizing data completeness\n",
    "summary = grouped.agg(\n",
    "    count_observed=('ds', 'count'),\n",
    "    start_date=('ds', 'min'),\n",
    "    end_date=('ds', 'max')\n",
    ").reset_index()\n",
    "\n",
    "summary['expected_count'] = (\n",
    "    (summary['end_date'].dt.to_period('M') - summary['start_date'].dt.to_period('M')).apply(lambda x: x.n) + 1\n",
    ")\n",
    "\n",
    "# Identifying which time series are irregular\n",
    "summary['is_irregular'] = summary['count_observed'] < summary['expected_count']\n",
    "\n",
    "filtered = summary[summary['is_irregular'] == True]\n",
    "display(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f6a5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking na\n",
    "future_values.isna ().sum ()\n",
    "metadata.isna ().sum ()\n",
    "sales_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd91235",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_merged = pd.merge(sales_data, metadata, on='unique_id', how='left')\n",
    "future_merged = pd.merge(future_values, metadata, on='unique_id', how='left')\n",
    "sales_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1236dedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure datetime\n",
    "sales_merged['ds'] = pd.to_datetime(sales_merged['ds'])\n",
    "\n",
    "# Create a weekly bucket\n",
    "sales_merged['week'] = sales_merged['ds'].dt.to_period('W-MON').dt.start_time\n",
    "\n",
    "# Make sure state_holiday is string type\n",
    "sales_merged['state_holiday'] = sales_merged['state_holiday'].astype(str)\n",
    "\n",
    "# Count how many times each state_holiday type appears per week per store\n",
    "holiday_counts = (\n",
    "    sales_merged\n",
    "    .groupby(['unique_id', 'week', 'state_holiday'])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)  # turns into columns\n",
    "    .reset_index()\n",
    "    .rename_axis(None, axis=1)  # remove column name\n",
    ")\n",
    "\n",
    "# Optional: Rename columns for clarity\n",
    "holiday_counts.columns = ['unique_id', 'week'] + [f'state_holiday_{col}' for col in holiday_counts.columns[2:]]\n",
    "\n",
    "# Now aggregate your normal weekly data\n",
    "weekly_data = sales_merged.groupby(['unique_id', 'week'], as_index=False).agg({\n",
    "    'y': 'sum',\n",
    "    'customers': 'sum',\n",
    "    'promo': 'sum',\n",
    "    'open': 'sum',\n",
    "    'school_holiday': 'sum',\n",
    "    'store_type': 'first',\n",
    "    'assortment': 'first',\n",
    "    'competition_distance': 'first'\n",
    "})\n",
    "\n",
    "# Merge the holiday counts in\n",
    "weekly_data = weekly_data.merge(holiday_counts, on=['unique_id', 'week'], how='left')\n",
    "\n",
    "# Fill in 0 where a holiday type didnâ€™t occur that week\n",
    "weekly_data.fillna(0, inplace=True)\n",
    "\n",
    "weekly_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fca3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_values = np.where((weekly_data['state_holiday_a']>0) & (weekly_data['state_holiday_b']> 0) & (weekly_data['state_holiday_c']>0))\n",
    "print(filtered_values)\n",
    "display(weekly_data.loc[filtered_values])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
